# SignBridge - Bridging the gap of Sign Language

A real-time American Sign Language (ASL) recognition system using computer vision and deep learning to translate hand gestures into text.

## âœ¨ Features

- **Real-time Recognition**: Live ASL gesture recognition through webcam
- **Hand Detection**: Accurate hand landmark detection using MediaPipe
- **Deep Learning Model**: Custom CNN model trained on ASL alphabet dataset
- **High Accuracy**: Optimized model for reliable gesture classification
- **User-friendly Interface**: Simple and intuitive real-time display
- **Confidence Scoring**: Shows prediction confidence for each gesture
- **Multi-platform**: Works on Windows, macOS, and Linux

## ğŸ›  Tech Stack

### Machine Learning & AI
- **TensorFlow/Keras** - Deep learning framework for model training and inference
- **MediaPipe** - Hand landmark detection and tracking
- **NumPy** - Numerical computations and array operations

### Computer Vision
- **OpenCV** - Real-time computer vision and image processing
- **PIL/Pillow** - Image manipulation and preprocessing

### Model Architecture
- **MobileNetV2** - Efficient CNN architecture for real-time inference
- **Transfer Learning** - Pre-trained weights fine-tuned for ASL recognition
- **Data Augmentation** - Enhanced training with image transformations

### Development Tools
- **Python 3.11+** - Primary programming language
- **Jupyter Notebooks** - Model development and experimentation
- **Git** - Version control

## ğŸš€ Installation

1. **Clone the repository**
```bash
git clone https://github.com/sudiptasarkar011/sign-language.git
cd sign-language
```

2. **Create virtual environment**
```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

## ğŸ¯ Usage

### Real-time Recognition
```bash
python realtime.py
```
- Point your webcam at ASL hand gestures
- The system will detect and classify gestures in real-time
- Press 'q' to quit the application

### Training Your Own Model
```bash
python train.py
```
- Ensure your dataset is organized in the correct folder structure
- The script will train a new model and save it as `asl_mobilenet_full.keras`

## ğŸ“ Project Structure

```
sign-language/
â”œâ”€â”€ realtime.py              # Real-time recognition script
â”œâ”€â”€ train.py                 # Model training script
â”œâ”€â”€ asl_mobilenet_full.keras # Pre-trained model
â”œâ”€â”€ classes.txt              # Class labels
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ Demo.mov                 # Demo video
â”œâ”€â”€ main.ipynb              # Jupyter notebook for experimentation
â””â”€â”€ README.md               # This file
```

## ğŸ¬ How It Works

1. **Hand Detection**: MediaPipe detects hand landmarks in real-time
2. **Region Extraction**: Extracts hand region with bounding box
3. **Preprocessing**: Resizes and normalizes the image for model input
4. **Prediction**: MobileNetV2 model classifies the gesture
5. **Display**: Shows the predicted letter with confidence score

## ğŸ“Š Model Performance

- **Architecture**: MobileNetV2-based CNN
- **Input Size**: 160x160 RGB images
- **Classes**: 26 ASL alphabet letters
- **Accuracy**: ~95%+ on test dataset
- **Inference Speed**: Real-time (30+ FPS)

## ğŸ”§ Configuration

You can modify the following parameters in `realtime.py`:

```python
IMG_SIZE = (160, 160)        # Input image size for model
min_detection_confidence=0.6  # Hand detection threshold
min_tracking_confidence=0.5   # Hand tracking threshold
prediction_threshold=0.5      # Minimum confidence for predictions
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- MediaPipe team for the excellent hand detection framework
- TensorFlow team for the deep learning framework
- ASL alphabet dataset contributors
- Open source community for various tools and libraries

## ğŸ“§ Contact

**Sudipta Sarkar**
- GitHub: [@kartavya4874](https://github.com/kartavya4874)
- Email: kartavyabaluja453@gmail.com

---

â­ If you found this project helpful, please give it a star!
